{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First is necessary to know which files are going to be used in the data set, in our case we tried to use all the information avaiable (so we should have 1012 patient id's inside our local copy of the LIDC-IDRI) so that we could get more accurate results and since we would be using \"one\" image from each pacient \"nodule\". Also we need the Patients ID's so that we can have access to the scan's, conveniently the names of the folders inside the LIDC-IDRI correspond to the Patient ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in the dataset: 1010\n",
      "\n",
      "List of the id's that are missing from our dataset:\n",
      "LIDC-IDRI-0239\n",
      "LIDC-IDRI-0586\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#specify the path to your dataset where you have the folders with the name of the pacients\n",
    "directory=\"data/dataset/LIDC-IDRI/\"\n",
    "#list all the folders inside our local copy of LIDC-IDRI (that correspond to the patient id's that are going to be used to get the scans and annotations)\n",
    "folders=os.listdir(directory)\n",
    "\n",
    "print(f\"Number of patients in the dataset: {len(folders)}\")\n",
    "#just so that it is easier to know which patients we are don't have in our copy of the LIDC-IDRI\n",
    "folders.sort()\n",
    "print()\n",
    "#printing the patients id's that we couldn't download\n",
    "print(\"List of the id's that are missing from our dataset:\")\n",
    "count=1\n",
    "for folder in folders:\n",
    "    if(str(count) not in folder):\n",
    "        print(folder)\n",
    "        count=int(folder.split('-')[-1])\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is possible to see the number is diferent from the expected (1012 number of people that are avaiable in the original LODC-IRDI), this is due to the fact that during the download (which was made using the offical tool nbia-data-retriver) we did not have authority to download this instances, one reason could be the patient's own choice, since this number is only the possible data loss is should not impact our conclusions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylidc as pl\n",
    "\n",
    "n_lesions=0\n",
    "scans_0_nods=[]\n",
    "\n",
    "for folder in folders:\n",
    "    pid=folder\n",
    "\n",
    "    #get the scann corresponding to the patient_id that we have \n",
    "    scan=pl.query(pl.Scan).filter(pl.Scan.patient_id==pid).first()\n",
    "    #get all the nodules annotations, each list corresponds to the same nodules\n",
    "    nods=scan.cluster_annotations()    \n",
    "    n_lesions+=len(nods)\n",
    "    if(len(nods)==0):\n",
    "        scans_0_nods.append([scan.patient_id,scan.annotations])\n",
    "        \n",
    "\n",
    "\n",
    "print(f\"Number of lesions: {n_lesions}\" )\n",
    "print(f\"Number of scanns with 0 nodules: {len(scans_0_nods)}\")\n",
    "#print(scans_0_nods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the code above the output should be:\n",
    "\n",
    "Number of lesions: 2625                                                                                                                                                  \n",
    "Number of scanns with 0 annotations: 135 (13 of these gave an error in the clustering to the nearest nodule so they have annotations but we would have to adjust them to the manually to one of the nodes present)\n",
    "\n",
    "Note: The output of the cell was cleared because of the error message of the 13 scanns mentioned, jsut so the notebook wouldn't be clutterd\n",
    "\n",
    "This code only serves to give us the numbers of rows that ours datasets should have if everything runs without errors, and how many more scans are not going to used.This is because if an scan doesn't have annotations we are incappable of knowing many informations that are required for it to be part of the dataset (for example the malignancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function simply gets the malignancy of an nodule.It is a crucial part of our project since it is this malignancy value that is going to be used as a Label for our classes. Using pylidc we can get this value easily since for each scann we have access to it's annotations, and in each annotation we have one value for malignancy given by an radiologist. In order to get an more precise value for the malignancy we calculate the mean between the diferent annotations, since getting that value from a single annotation could introduce the bias of that radiologist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_malignancy(anns):\n",
    "    #Get the Malignancy of the lesion\n",
    "    #\n",
    "    #   1-‘Highly Unlikely’\n",
    "    #   2-‘Moderately Unlikely’\n",
    "    #   3-‘Indeterminate’\n",
    "    #   4-‘Moderately Suspicious’\n",
    "    #   5-‘Highly Suspicious’\n",
    "    #this feature will be used as a label to the dataset\n",
    "    malignancy=0\n",
    "    for i in range(len(anns)):\n",
    "        malignancy+=anns[i].malignancy\n",
    "    malignancy/=len(anns)\n",
    "    malignancy=round(malignancy)\n",
    "\n",
    "    return malignancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the get_malignancy function it also uses annotations and the pylidc library to get the values of calcification, once again we calculate the mean to get a value that better represents the reality. Getting the calcification of the nodule is beneficial for our model since it indicates a high probability that the lesion is benign, it's not always the case but it is a pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calcification(anns):\n",
    "    #Get the pattern of calcification if present\n",
    "    # \n",
    "    #   1-‘Popcorn’\n",
    "    #   2-‘Laminated’\n",
    "    #   3-‘Solid’\n",
    "    #   4-‘Non-central’\n",
    "    #   5-‘Central’\n",
    "    #   6-‘Absent’\n",
    "    calcification=0\n",
    "    for i in range(len(anns)):\n",
    "        calcification+=anns[i].calcification\n",
    "    calcification/=len(anns)\n",
    "    calcification=round(calcification)\n",
    "    return calcification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function get_lobulation works exactly as the previous but it gets the lobutation value. It can give an us an idea of the growth rates of an nodules, which can be indicators of malignancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lobulation(anns):\n",
    "    #Get the degree of lobulationof the lesion\n",
    "    #\n",
    "    #   1-‘No Lobulation’\n",
    "    #   2-‘Nearly No Lobulation’\n",
    "    #   3-‘Medium Lobulation’\n",
    "    #   4-‘Near Marked Lobulation’\n",
    "    #   5-‘Marked Lobulation’\n",
    "\n",
    "    lobulation=0\n",
    "    for i in range(len(anns)):\n",
    "        lobulation+=anns[i].lobulation\n",
    "    lobulation/=len(anns)\n",
    "    lobulation=round(lobulation)\n",
    "    return lobulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarily to lobulation spiculation is an indicator of growth rates, it is normaly associated with irregular and \"spiky\" margins, indicating uneven growth rates which are one of the main poiter to the malignancy of a nodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spiculation(anns):\n",
    "    #Get the extent of spiculation present in the lesion\n",
    "    #\n",
    "    #   ‘No Spiculation’\n",
    "    #   ‘Nearly No Spiculation’\n",
    "    #   ‘Medium Spiculation’\n",
    "    #   ‘Near Marked Spiculation’\n",
    "    #   ‘Marked Spiculation’\n",
    "    spiculation=0\n",
    "    for i in range(len(anns)):\n",
    "        spiculation+=anns[i].spiculation\n",
    "    spiculation/=len(anns)\n",
    "    spiculation=round(spiculation)\n",
    "    return spiculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internal Texture of an nodule can gives us informtation that goes beyond the geometric form of the nodule, as a result we decided to also include it in our analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_internal_texture(anns):\n",
    "    #Get the internal texture of the lesion\n",
    "    #\n",
    "    #    1-‘Non-Solid/GGO’\n",
    "    #    2-‘Non-Solid/Mixed’\n",
    "    #    3-‘Part Solid/Mixed’\n",
    "    #    4-‘Solid/Mixed’\n",
    "    #    5-‘Solid’\n",
    "    texture=0\n",
    "    for i in range(len(anns)):\n",
    "        texture+=anns[i].texture\n",
    "    texture/=len(anns)\n",
    "    texture=round(texture)\n",
    "    return texture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple features that give an idea of the size of the node, even if we know previously that since it has annotation it has to be >3mm being more precise with the size can be usefull for our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diameter_surface_area_volume(anns):\n",
    "    #Get the mean value of all anotations for this lesion of the diameter, surface_area, volume\n",
    "    diameter=0\n",
    "    surface_area=0\n",
    "    volume=0\n",
    "    for i in range(len(anns)):\n",
    "        diameter+=anns[i].diameter\n",
    "        surface_area+=anns[i].surface_area\n",
    "        volume+=anns[i].volume\n",
    "    diameter/=len(anns)\n",
    "    surface_area/=len(anns)\n",
    "    volume/=len(anns)\n",
    "\n",
    "    return diameter,surface_area,volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also gives an idea of size, but this time it ins't as regularized, since it is not in an any metric unit. It could also capture diference in machines, all the images are the same resolution, which should mean that if we have the same pixeis inside an nodule they should have the same volume, but since in the LIDC-IDRI various diferent machines were used that dirence could mean that the volumes are not equal. We calculate this value using an mask calculated via concensus of all the masks created by the radilogist who made annotations for that nodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_pixeis_in(cmask):\n",
    "    #Calculating the number of pixeis inside a lesion\n",
    "    return np.sum(cmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function we calculate the overall circularity of the nodule acrros all of the slices, this is done onde more with the concensus mask. Circularity is an important attribute to capture for the same reasons of the lobulation and spiculation, it can indicate an uneven growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel\n",
    "\n",
    "def get_circularity(cmask):\n",
    "    # Calculate circularity\n",
    "    # the closer to 1 the closer to a perfect circle\n",
    "    circularity=0\n",
    "    for i in range(cmask.shape[-1]):\n",
    "        area_k_slice_pixels=np.sum(cmask[:,:,i])#this way we get the number of pixeis of the k\n",
    "        # Calculating the perimeter(in pixels) by appling an edge filter to the mask\n",
    "        edges=sobel(cmask)\n",
    "        perimeter_piexels=np.sum(edges[:,:,i])#so that we get the perimeter of the slice i of the lesion\n",
    "        if(perimeter_piexels==0):\n",
    "            circularity+=0\n",
    "        else:\n",
    "            circularity += (4 * np.pi * area_k_slice_pixels) / (perimeter_piexels ** 2)\n",
    "    circularity/=cmask.shape[-1]\n",
    "\n",
    "    return circularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the following functions: get_median_  |  get_std_  |  get_var_  |  get_mean\n",
    "Use HU to get information about radiodensity of diferent tissues hopefully to understand what kind of tissues are insede the nodule. They are canculate since using pylidc we can get the HU of the scan, then we crop the image to the relevant part to the nodule being analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_hu(nodule_hu_values):\n",
    "    #Calculate the median HU inside of the lesion\n",
    "    #vol[ccbox][cmask] represents the HU inside the lesion\n",
    "    return np.median(nodule_hu_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_hu(nodule_hu_values):\n",
    "    #Calculate the the standard variation of HU inside the lesion\n",
    "    return np.std(nodule_hu_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_hu(nodule_hu_values):\n",
    "    #Calculate the variance of HU inside the lesion\n",
    "    return np.var(nodule_hu_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_hu(nodule_hu_values):\n",
    "    #Calculate the mean of HU inside the lesion\n",
    "    return np.mean(nodule_hu_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code bellow is the onde responsible for getting all the information for each nodule. It gets Patient ID associated to an folder gets the scan and annotations of that patient and then it calculates all the features discussed above. For each nodule it also uses the cnn VG16 to try and extract even more features, we chose the VG16 because of the simple architecture and the fact that is pre-trained using the the weights of the imagenet dataset which is one of largest images datasets avaiable, although it isn't trainned specifically for medic imaging it was shown to have an good performance. We also try to use Global Average Pooling in an attempt to make the impact of the \"curse of dimentionality\" not be so severe. Also because of that, the original idea of filtering the original image of the nodule with an entropy and sobel filter to then fedd the VG16 was scrapped, as it would not only give us even more features that could redundant and would make the computational cost of this step even higher \n",
    "Note:This cell of code averages an run time of 80 min with an laptop pluged in, if you want to run it we advise to have the computer not be running of battery as it will increase the run time to 120 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pylidc.utils import consensus\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#load pre-trained model withput the top layers\n",
    "base_model=VGG16(weights='imagenet',include_top=False, input_shape=(512,512,3))\n",
    "\n",
    "#add global pooling to the method\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "cnn_model=Model(inputs=base_model.input,outputs=x)\n",
    "\n",
    "\n",
    "#create the DataFrame where we ccn features are going to be stored\n",
    "\n",
    "#create the columns names\n",
    "columns_name=[\"PatientID\",\n",
    "              \"Calcification\",\n",
    "              \"Lobulation\",\n",
    "              \"Spiculation\",\n",
    "              \"Internal Texture\",\n",
    "              \"Diameter (mm)\",\n",
    "              \"Surface Area (mm^2)\",\n",
    "              \"Volume (mm^3)\",\n",
    "              \"Pixeis_in_lesion\",\n",
    "              \"Circularity\",\n",
    "              \"Median_HU_in_lesion\",\n",
    "              \"STD_HU_in_lesion\",\n",
    "              \"VAR_HU_in_lession\",\n",
    "              \"Mean_HU_in_lesion\"\n",
    "              ]\n",
    "for i in range(512):\n",
    "    columns_name.append(\"cnn_feature \"+str(i))\n",
    "\n",
    "columns_name.append(\"Label\")\n",
    "\n",
    "df=pd.DataFrame(columns=columns_name)\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    \n",
    "    pid=folder\n",
    "    print(f\"Currently in scan: {pid}\")\n",
    "\n",
    "    #get the scann corresponding to the patient_id that we have \n",
    "    scan=pl.query(pl.Scan).filter(pl.Scan.patient_id==pid).first()\n",
    "    \n",
    "    #get all the nodules annotations, each list corresponds to the same lesions \n",
    "    nods=scan.cluster_annotations()\n",
    "    #nods is a list of list of annotations agrouped by nodule\n",
    "\n",
    "    #create an volume with all of the dicom images of that scan (basicly an 3D image of the CT)\n",
    "    vol=scan.to_volume()\n",
    "\n",
    "    padding=[(30,20),(10,25),(0,0)]\n",
    "    #anns represents all the annotations for one lesion in this scann\n",
    "    #nods represents a list of all the annotations for each lesion in this scan \n",
    "    for anns in nods:\n",
    "        #get the concensus for the contours of this nodule\n",
    "        cmask,cbbox,masks=consensus(anns,clevel=0.5,pad=padding)\n",
    "\n",
    "        #get the central slice of the computed bounding box\n",
    "        k=int(0.5*(cbbox[2].stop-cbbox[2].start))\n",
    "\n",
    "        img=vol[cbbox][:,:,k]\n",
    "\n",
    "\n",
    "        #applying possible usefull filters since we don't have that many lesions (2625)\n",
    "        from skimage.filters.rank import entropy\n",
    "        from skimage.morphology import disk\n",
    "        from skimage.util import img_as_ubyte\n",
    "        entropy_img=entropy(img_as_ubyte(img),disk(1))\n",
    "\n",
    "\n",
    "        from skimage.filters import sobel\n",
    "        sobel_img=sobel(img)\n",
    "\n",
    "        #getting the images ready for the cnn\n",
    "        imgs=[img,entropy_img,sobel_img]\n",
    "\n",
    "        for i in range(1):#we can change this after if we want to use the filters\n",
    "            #making each image have 3 dimensions\n",
    "            imgs[i] = np.expand_dims(imgs[i], axis=-1)\n",
    "\n",
    "            #resizing the images so that they match the input of the cnn\n",
    "            imgs[i]=tf.image.resize(imgs[i],(512,512))\n",
    "\n",
    "            #converting the images to rgb\n",
    "            if(imgs[i].shape[-1]==1):\n",
    "                imgs[i]=tf.image.grayscale_to_rgb(imgs[i])\n",
    "            \n",
    "            #preprocess to the VGG16\n",
    "            imgs[i]=preprocess_input(imgs[i].numpy())\n",
    "\n",
    "            #get the features learned by the cnn\n",
    "            features=cnn_model(np.expand_dims(imgs[i], axis=0))\n",
    "            features=features.numpy().flatten()\n",
    "\n",
    "            #create the row with everything that is going in the dataset \n",
    "            row=[pid]\n",
    "            row.append(get_calcification(anns))\n",
    "            row.append(get_lobulation(anns))\n",
    "            row.append(get_spiculation(anns))\n",
    "            row.append(get_internal_texture(anns))\n",
    "            row.extend(get_diameter_surface_area_volume(anns))\n",
    "            row.append(get_pixeis_in(cmask))\n",
    "            row.append(get_circularity(cmask))\n",
    "            row.append(get_median_hu(vol[cbbox][cmask]))\n",
    "            row.append(get_std_hu(vol[cbbox][cmask]))\n",
    "            row.append(get_var_hu(vol[cbbox][cmask]))\n",
    "            row.append(get_mean_hu(vol[cbbox][cmask]))\n",
    "            #this are the cnn_extracted features\n",
    "            for x in features:\n",
    "                row.append(x)\n",
    "            #this is the label\n",
    "            row.append(get_malignancy(anns))\n",
    "            df.loc[len(df.index)]=row\n",
    "        \n",
    "    #     break #this breaks are for when debugging not having to run all the scanns\n",
    "    # break #this breaks are for when debugging not having to run all the scanns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the current cnn features values to make it possible to make use them without having to calculate them again as it can take a while (93 min first time we tried)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cnn+pylidc_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after using Global Average Pooling the output of our CNN is 512 feature which is way too high. So we need to reduce it even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2625, 527)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Lobulation</th>\n",
       "      <th>Spiculation</th>\n",
       "      <th>Internal Texture</th>\n",
       "      <th>Diameter (mm)</th>\n",
       "      <th>Surface Area (mm^2)</th>\n",
       "      <th>Volume (mm^3)</th>\n",
       "      <th>Pixeis_in_lesion</th>\n",
       "      <th>Circularity</th>\n",
       "      <th>...</th>\n",
       "      <th>cnn_feature 503</th>\n",
       "      <th>cnn_feature 504</th>\n",
       "      <th>cnn_feature 505</th>\n",
       "      <th>cnn_feature 506</th>\n",
       "      <th>cnn_feature 507</th>\n",
       "      <th>cnn_feature 508</th>\n",
       "      <th>cnn_feature 509</th>\n",
       "      <th>cnn_feature 510</th>\n",
       "      <th>cnn_feature 511</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIDC-IDRI-0001</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32.755812</td>\n",
       "      <td>2491.466573</td>\n",
       "      <td>6989.673615</td>\n",
       "      <td>5428</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080818</td>\n",
       "      <td>1.799512</td>\n",
       "      <td>0.474278</td>\n",
       "      <td>6.975934</td>\n",
       "      <td>1.273983</td>\n",
       "      <td>4.503269</td>\n",
       "      <td>0.129298</td>\n",
       "      <td>9.106273</td>\n",
       "      <td>0.563464</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIDC-IDRI-0002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.781671</td>\n",
       "      <td>2807.198994</td>\n",
       "      <td>7244.667508</td>\n",
       "      <td>14252</td>\n",
       "      <td>0.243756</td>\n",
       "      <td>...</td>\n",
       "      <td>3.473532</td>\n",
       "      <td>0.753911</td>\n",
       "      <td>0.949201</td>\n",
       "      <td>1.776874</td>\n",
       "      <td>2.387758</td>\n",
       "      <td>4.194271</td>\n",
       "      <td>1.476390</td>\n",
       "      <td>5.335127</td>\n",
       "      <td>1.748041</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.664468</td>\n",
       "      <td>1996.252117</td>\n",
       "      <td>4731.410934</td>\n",
       "      <td>2542</td>\n",
       "      <td>0.154584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801210</td>\n",
       "      <td>0.239504</td>\n",
       "      <td>9.201927</td>\n",
       "      <td>1.946184</td>\n",
       "      <td>5.459285</td>\n",
       "      <td>0.320320</td>\n",
       "      <td>0.616315</td>\n",
       "      <td>3.036831</td>\n",
       "      <td>0.429381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>31.001964</td>\n",
       "      <td>2225.677350</td>\n",
       "      <td>6519.463698</td>\n",
       "      <td>3241</td>\n",
       "      <td>0.139765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951502</td>\n",
       "      <td>1.994685</td>\n",
       "      <td>0.370287</td>\n",
       "      <td>5.199282</td>\n",
       "      <td>1.392501</td>\n",
       "      <td>1.789750</td>\n",
       "      <td>0.671943</td>\n",
       "      <td>5.783095</td>\n",
       "      <td>0.068551</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13.309155</td>\n",
       "      <td>321.183599</td>\n",
       "      <td>472.089669</td>\n",
       "      <td>261</td>\n",
       "      <td>0.271896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095775</td>\n",
       "      <td>1.139045</td>\n",
       "      <td>0.818399</td>\n",
       "      <td>4.912726</td>\n",
       "      <td>11.126127</td>\n",
       "      <td>1.109776</td>\n",
       "      <td>1.508004</td>\n",
       "      <td>11.945731</td>\n",
       "      <td>0.484690</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PatientID  Calcification  Lobulation  Spiculation  Internal Texture  \\\n",
       "0  LIDC-IDRI-0001              6           3            4                 5   \n",
       "1  LIDC-IDRI-0002              6           1            1                 2   \n",
       "2  LIDC-IDRI-0003              6           1            1                 1   \n",
       "3  LIDC-IDRI-0003              6           2            3                 4   \n",
       "4  LIDC-IDRI-0003              6           2            2                 5   \n",
       "\n",
       "   Diameter (mm)  Surface Area (mm^2)  Volume (mm^3)  Pixeis_in_lesion  \\\n",
       "0      32.755812          2491.466573    6989.673615              5428   \n",
       "1      30.781671          2807.198994    7244.667508             14252   \n",
       "2      31.664468          1996.252117    4731.410934              2542   \n",
       "3      31.001964          2225.677350    6519.463698              3241   \n",
       "4      13.309155           321.183599     472.089669               261   \n",
       "\n",
       "   Circularity  ...  cnn_feature 503  cnn_feature 504  cnn_feature 505  \\\n",
       "0     0.121212  ...         0.080818         1.799512         0.474278   \n",
       "1     0.243756  ...         3.473532         0.753911         0.949201   \n",
       "2     0.154584  ...         0.801210         0.239504         9.201927   \n",
       "3     0.139765  ...         0.951502         1.994685         0.370287   \n",
       "4     0.271896  ...         0.095775         1.139045         0.818399   \n",
       "\n",
       "   cnn_feature 506  cnn_feature 507  cnn_feature 508  cnn_feature 509  \\\n",
       "0         6.975934         1.273983         4.503269         0.129298   \n",
       "1         1.776874         2.387758         4.194271         1.476390   \n",
       "2         1.946184         5.459285         0.320320         0.616315   \n",
       "3         5.199282         1.392501         1.789750         0.671943   \n",
       "4         4.912726        11.126127         1.109776         1.508004   \n",
       "\n",
       "   cnn_feature 510  cnn_feature 511  Label  \n",
       "0         9.106273         0.563464      5  \n",
       "1         5.335127         1.748041      4  \n",
       "2         3.036831         0.429381      2  \n",
       "3         5.783095         0.068551      4  \n",
       "4        11.945731         0.484690      3  \n",
       "\n",
       "[5 rows x 527 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('cnn+pylidc_features.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the randomforest algorithm to work better we decided to make the number of features smaller 200 and 50, using PCA. Which basicly is going to choose the principal componets having into account their variance and covariance to understand if certain features overlap and which ones represent more overall variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2625, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=50)\n",
    "features_columns=df.loc[:,~df.columns.isin(['PatientID','Label',\"Calcification\",\n",
    "              \"Lobulation\",\n",
    "              \"Spiculation\",\n",
    "              \"Internal Texture\",\n",
    "              \"Diameter (mm)\",\n",
    "              \"Surface Area (mm^2)\",\n",
    "              \"Volume (mm^3)\",\n",
    "              \"Pixeis_in_lesion\",\n",
    "              \"Circularity\",\n",
    "              \"Median_HU_in_lesion\",\n",
    "              \"STD_HU_in_lesion\",\n",
    "              \"VAR_HU_in_lession\",\n",
    "              \"Mean_HU_in_lesion\"])]\n",
    "reduced_features=pca.fit_transform(features_columns)\n",
    "reduced_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formating the reduced features into an DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Lobulation</th>\n",
       "      <th>Spiculation</th>\n",
       "      <th>Internal Texture</th>\n",
       "      <th>Diameter (mm)</th>\n",
       "      <th>Surface Area (mm^2)</th>\n",
       "      <th>Volume (mm^3)</th>\n",
       "      <th>Pixeis_in_lesion</th>\n",
       "      <th>Circularity</th>\n",
       "      <th>...</th>\n",
       "      <th>cnn_feature 41</th>\n",
       "      <th>cnn_feature 42</th>\n",
       "      <th>cnn_feature 43</th>\n",
       "      <th>cnn_feature 44</th>\n",
       "      <th>cnn_feature 45</th>\n",
       "      <th>cnn_feature 46</th>\n",
       "      <th>cnn_feature 47</th>\n",
       "      <th>cnn_feature 48</th>\n",
       "      <th>cnn_feature 49</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIDC-IDRI-0001</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32.755812</td>\n",
       "      <td>2491.466573</td>\n",
       "      <td>6989.673615</td>\n",
       "      <td>5428</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>7.040247</td>\n",
       "      <td>-1.513496</td>\n",
       "      <td>0.775723</td>\n",
       "      <td>-0.234806</td>\n",
       "      <td>-5.807555</td>\n",
       "      <td>-3.458864</td>\n",
       "      <td>-4.258366</td>\n",
       "      <td>4.971976</td>\n",
       "      <td>-1.937084</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIDC-IDRI-0002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.781671</td>\n",
       "      <td>2807.198994</td>\n",
       "      <td>7244.667508</td>\n",
       "      <td>14252</td>\n",
       "      <td>0.243756</td>\n",
       "      <td>...</td>\n",
       "      <td>3.515642</td>\n",
       "      <td>5.453791</td>\n",
       "      <td>-4.427953</td>\n",
       "      <td>-4.131188</td>\n",
       "      <td>-2.238985</td>\n",
       "      <td>-0.942886</td>\n",
       "      <td>-7.291642</td>\n",
       "      <td>7.063912</td>\n",
       "      <td>4.522726</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.664468</td>\n",
       "      <td>1996.252117</td>\n",
       "      <td>4731.410934</td>\n",
       "      <td>2542</td>\n",
       "      <td>0.154584</td>\n",
       "      <td>...</td>\n",
       "      <td>5.648545</td>\n",
       "      <td>-5.778849</td>\n",
       "      <td>-2.962466</td>\n",
       "      <td>6.492604</td>\n",
       "      <td>-3.243713</td>\n",
       "      <td>-0.093044</td>\n",
       "      <td>-7.528972</td>\n",
       "      <td>1.491716</td>\n",
       "      <td>-5.227047</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>31.001964</td>\n",
       "      <td>2225.677350</td>\n",
       "      <td>6519.463698</td>\n",
       "      <td>3241</td>\n",
       "      <td>0.139765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395001</td>\n",
       "      <td>-0.695193</td>\n",
       "      <td>-0.807704</td>\n",
       "      <td>1.977416</td>\n",
       "      <td>-2.345557</td>\n",
       "      <td>-1.399320</td>\n",
       "      <td>-3.947806</td>\n",
       "      <td>9.112702</td>\n",
       "      <td>-2.307368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13.309155</td>\n",
       "      <td>321.183599</td>\n",
       "      <td>472.089669</td>\n",
       "      <td>261</td>\n",
       "      <td>0.271896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.828549</td>\n",
       "      <td>-1.749191</td>\n",
       "      <td>-3.188446</td>\n",
       "      <td>-0.763180</td>\n",
       "      <td>0.101668</td>\n",
       "      <td>-0.589906</td>\n",
       "      <td>1.837360</td>\n",
       "      <td>-0.556560</td>\n",
       "      <td>-2.447910</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PatientID  Calcification  Lobulation  Spiculation  Internal Texture  \\\n",
       "0  LIDC-IDRI-0001              6           3            4                 5   \n",
       "1  LIDC-IDRI-0002              6           1            1                 2   \n",
       "2  LIDC-IDRI-0003              6           1            1                 1   \n",
       "3  LIDC-IDRI-0003              6           2            3                 4   \n",
       "4  LIDC-IDRI-0003              6           2            2                 5   \n",
       "\n",
       "   Diameter (mm)  Surface Area (mm^2)  Volume (mm^3)  Pixeis_in_lesion  \\\n",
       "0      32.755812          2491.466573    6989.673615              5428   \n",
       "1      30.781671          2807.198994    7244.667508             14252   \n",
       "2      31.664468          1996.252117    4731.410934              2542   \n",
       "3      31.001964          2225.677350    6519.463698              3241   \n",
       "4      13.309155           321.183599     472.089669               261   \n",
       "\n",
       "   Circularity  ...  cnn_feature 41  cnn_feature 42  cnn_feature 43  \\\n",
       "0     0.121212  ...        7.040247       -1.513496        0.775723   \n",
       "1     0.243756  ...        3.515642        5.453791       -4.427953   \n",
       "2     0.154584  ...        5.648545       -5.778849       -2.962466   \n",
       "3     0.139765  ...       -0.395001       -0.695193       -0.807704   \n",
       "4     0.271896  ...       -1.828549       -1.749191       -3.188446   \n",
       "\n",
       "   cnn_feature 44  cnn_feature 45  cnn_feature 46  cnn_feature 47  \\\n",
       "0       -0.234806       -5.807555       -3.458864       -4.258366   \n",
       "1       -4.131188       -2.238985       -0.942886       -7.291642   \n",
       "2        6.492604       -3.243713       -0.093044       -7.528972   \n",
       "3        1.977416       -2.345557       -1.399320       -3.947806   \n",
       "4       -0.763180        0.101668       -0.589906        1.837360   \n",
       "\n",
       "   cnn_feature 48  cnn_feature 49  Label  \n",
       "0        4.971976       -1.937084      5  \n",
       "1        7.063912        4.522726      4  \n",
       "2        1.491716       -5.227047      2  \n",
       "3        9.112702       -2.307368      4  \n",
       "4       -0.556560       -2.447910      3  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_name=[]\n",
    "for i in range(50):\n",
    "    columns_name.append(\"cnn_feature \"+str(i))\n",
    "    \n",
    "reduced_df=pd.DataFrame(columns=columns_name, data=reduced_features)\n",
    "reduced_df=pd.concat([df[['PatientID',\"Calcification\",\n",
    "              \"Lobulation\",\n",
    "              \"Spiculation\",\n",
    "              \"Internal Texture\",\n",
    "              \"Diameter (mm)\",\n",
    "              \"Surface Area (mm^2)\",\n",
    "              \"Volume (mm^3)\",\n",
    "              \"Pixeis_in_lesion\",\n",
    "              \"Circularity\",\n",
    "              \"Median_HU_in_lesion\",\n",
    "              \"STD_HU_in_lesion\",\n",
    "              \"VAR_HU_in_lession\",\n",
    "              \"Mean_HU_in_lesion\"]],reduced_df,df['Label']], axis=1)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2625, 65)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the reduced dataset for easy access to both the full set of features and the reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the reduced cnn_features\n",
    "reduced_df.to_csv('cnn_reduced_50+pylidc_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparation sake we created an dataset without the cnn features to understand if they are ginving new information to our preditive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2625, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Lobulation</th>\n",
       "      <th>Spiculation</th>\n",
       "      <th>Internal Texture</th>\n",
       "      <th>Diameter (mm)</th>\n",
       "      <th>Surface Area (mm^2)</th>\n",
       "      <th>Volume (mm^3)</th>\n",
       "      <th>Pixeis_in_lesion</th>\n",
       "      <th>Circularity</th>\n",
       "      <th>Median_HU_in_lesion</th>\n",
       "      <th>STD_HU_in_lesion</th>\n",
       "      <th>VAR_HU_in_lession</th>\n",
       "      <th>Mean_HU_in_lesion</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIDC-IDRI-0001</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32.755812</td>\n",
       "      <td>2491.466573</td>\n",
       "      <td>6989.673615</td>\n",
       "      <td>5428</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>224.079908</td>\n",
       "      <td>50211.805256</td>\n",
       "      <td>-77.425571</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIDC-IDRI-0002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.781671</td>\n",
       "      <td>2807.198994</td>\n",
       "      <td>7244.667508</td>\n",
       "      <td>14252</td>\n",
       "      <td>0.243756</td>\n",
       "      <td>-725.0</td>\n",
       "      <td>133.215507</td>\n",
       "      <td>17746.371374</td>\n",
       "      <td>-703.924993</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.664468</td>\n",
       "      <td>1996.252117</td>\n",
       "      <td>4731.410934</td>\n",
       "      <td>2542</td>\n",
       "      <td>0.154584</td>\n",
       "      <td>-660.0</td>\n",
       "      <td>142.814992</td>\n",
       "      <td>20396.121845</td>\n",
       "      <td>-640.765932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>31.001964</td>\n",
       "      <td>2225.677350</td>\n",
       "      <td>6519.463698</td>\n",
       "      <td>3241</td>\n",
       "      <td>0.139765</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>218.552088</td>\n",
       "      <td>47765.015033</td>\n",
       "      <td>-179.850663</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIDC-IDRI-0003</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13.309155</td>\n",
       "      <td>321.183599</td>\n",
       "      <td>472.089669</td>\n",
       "      <td>261</td>\n",
       "      <td>0.271896</td>\n",
       "      <td>-405.0</td>\n",
       "      <td>232.023157</td>\n",
       "      <td>53834.745526</td>\n",
       "      <td>-359.831418</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PatientID  Calcification  Lobulation  Spiculation  Internal Texture  \\\n",
       "0  LIDC-IDRI-0001              6           3            4                 5   \n",
       "1  LIDC-IDRI-0002              6           1            1                 2   \n",
       "2  LIDC-IDRI-0003              6           1            1                 1   \n",
       "3  LIDC-IDRI-0003              6           2            3                 4   \n",
       "4  LIDC-IDRI-0003              6           2            2                 5   \n",
       "\n",
       "   Diameter (mm)  Surface Area (mm^2)  Volume (mm^3)  Pixeis_in_lesion  \\\n",
       "0      32.755812          2491.466573    6989.673615              5428   \n",
       "1      30.781671          2807.198994    7244.667508             14252   \n",
       "2      31.664468          1996.252117    4731.410934              2542   \n",
       "3      31.001964          2225.677350    6519.463698              3241   \n",
       "4      13.309155           321.183599     472.089669               261   \n",
       "\n",
       "   Circularity  Median_HU_in_lesion  STD_HU_in_lesion  VAR_HU_in_lession  \\\n",
       "0     0.121212                 24.0        224.079908       50211.805256   \n",
       "1     0.243756               -725.0        133.215507       17746.371374   \n",
       "2     0.154584               -660.0        142.814992       20396.121845   \n",
       "3     0.139765               -104.0        218.552088       47765.015033   \n",
       "4     0.271896               -405.0        232.023157       53834.745526   \n",
       "\n",
       "   Mean_HU_in_lesion  Label  \n",
       "0         -77.425571      5  \n",
       "1        -703.924993      4  \n",
       "2        -640.765932      2  \n",
       "3        -179.850663      4  \n",
       "4        -359.831418      3  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataset without the cnn features\n",
    "pylidc_df=df[['PatientID',\"Calcification\",\n",
    "              \"Lobulation\",\n",
    "              \"Spiculation\",\n",
    "              \"Internal Texture\",\n",
    "              \"Diameter (mm)\",\n",
    "              \"Surface Area (mm^2)\",\n",
    "              \"Volume (mm^3)\",\n",
    "              \"Pixeis_in_lesion\",\n",
    "              \"Circularity\",\n",
    "              \"Median_HU_in_lesion\",\n",
    "              \"STD_HU_in_lesion\",\n",
    "              \"VAR_HU_in_lession\",\n",
    "              \"Mean_HU_in_lesion\",\"Label\"]]\n",
    "\n",
    "print(pylidc_df.shape)\n",
    "pylidc_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store it for easier access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the dataset without cnn features\n",
    "pylidc_df.to_csv(\"pylidc_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wnat to map the Labels because having 5 classes is not realy necessary, for example if an nodule is an 1 or an 2 it still is not considered Suspicious by radiologist. Other mappings also appeared to make sense like an nodule is either suspicous, not suspicous or we don't have enough infomation. Due to the fact that the class 3 considerated not enough information and the class 2 moderatly not suspicous are the most common one by far, and also because our predimitve model seemed to have problems distinguishing  both of them we decided we could put the class 2 inside the class 3 as if it is moderalty not suspicous there is no danger in cosider it not enough information because no agressive treatments would be prescribed either way and if anything it being class 3 it would just be put on an whatch list to be further analysed another time. Another idea to that problem was only using tow classes 1 and 5, however since the class 3 was a big part of our dataset we didn't want to simply not used and as such we created two label one in which the class 3 would be inside the class 1 (an conservative aproach because if we don't have enough information is better to say that it is not suspicious and avoid agreesive treatments) and one where the class 3 is inside the class 5(more agressive approach since it would say suspicous if it is in \"doubt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('datasets/cnn_reduced_50+pylidc_features.csv')\n",
    "#define the mapping desired\n",
    "# mapping 1\n",
    "#label_mapping= {1:1, 2:1, 3:3, 4:5, 5:5}\n",
    "# mapping 2\n",
    "#label_mapping= {1:1, 2:3, 3:3, 4:5, 5:5}\n",
    "# mapping 3\n",
    "#label_mapping= {1:1, 2:1, 3:5, 4:5, 5:5}\n",
    "# mapping 4\n",
    "label_mapping= {1:1, 2:1, 3:1, 4:5, 5:5}\n",
    "\n",
    "\n",
    "#aplying it \n",
    "df['Label']=df['Label'].map(label_mapping)\n",
    "\n",
    "df.to_csv('datasets/cnn_reduced_50+pylidc_features_nl4.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
